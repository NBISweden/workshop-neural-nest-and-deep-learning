{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras intro exercises\n",
    "\n",
    "## 1. Build a simple sequential model\n",
    "\n",
    "* Can you build a sequential model to reproduce the graph shown in the figure? \n",
    "* Assume that this is a classifier\n",
    "* Choose whatever activations you want, wherever possible\n",
    "* How many classes are we predicting?\n",
    "\n",
    "<center><img src=\"figures/sequence_api_exercise.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import #...\n",
    "\n",
    "#Add your model here\n",
    "\n",
    "plot_model(model, \"figures/exercise_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a better XOR classifier\n",
    "\n",
    "Given the model seen at lecture, how do we make a better classifier (higher accuracy)?\n",
    "\n",
    "* More layers? More neurons?\n",
    "* Generate more data?\n",
    "* More epochs?\n",
    "* Different batch size?\n",
    "* Different optimizer?\n",
    "* It's up to you! Let's see who does best on validation\n",
    "\n",
    "Only for Tuesday's session:\n",
    "\n",
    "* Different activations?\n",
    "* Add Dropout? How large?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training curve plotting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_loss_acc(history):\n",
    "    try:\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "    except:\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        \n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train acc', 'val acc', 'train loss', 'val loss'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.44 xor -0.14 xor  0.23 equals 0.0\n",
      "-0.17 xor -0.14 xor -0.33 equals 0.0\n",
      "-0.42 xor -0.33 xor -0.48 equals 0.0\n"
     ]
    }
   ],
   "source": [
    "# Generate XOR data\n",
    "data = np.random.random((10000, 3)) - 0.5\n",
    "labels = np.zeros((10000, 1))\n",
    "\n",
    "labels[np.where(np.logical_xor(np.logical_xor(data[:,0] > 0, data[:,1] > 0), data[:,2] > 0))] = 1\n",
    "\n",
    "#let's print some data and the corresponding label to check that they match the table above\n",
    "for x in range(3):\n",
    "    print(\"{0: .2f} xor {1: .2f} xor {2: .2f} equals {3:}\".format(data[x,0], data[x,1], data[x,2], labels[x,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The baseline network to improve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=3, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "history = model.fit(data, labels, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a regression model\n",
    "\n",
    "* Take the Boston housing dataset (http://lib.stat.cmu.edu/datasets/boston)\n",
    "* Records a set of variables for a set of houses in Boston, including among others:\n",
    "    * CRIM     per capita crime rate by town\n",
    "    * ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "    * INDUS    proportion of non-retail business acres per town\n",
    "    * CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "    * NOX      nitric oxides concentration (parts per 10 million)\n",
    "    * RM       average number of rooms per dwelling\n",
    "* Can we use these variables to predict the value of a house (in tens of thousands of dollars)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from sklearn.preprocessing import StandardScaler #hint\n",
    "\n",
    "#This is how we load the dataset, pre-split in training/validation sets\n",
    "(X_train, y_train), (X_val, y_val) = tensorflow.keras.datasets.boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=113)\n",
    "\n",
    "#Let's have a look at the data\n",
    "print(X_train.shape)\n",
    "print(X_train[0], y_train[0])\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(...)\n",
    "\n",
    "model.compile(...)\n",
    "history = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_mae(history, metric):\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(history.history[metric])\n",
    "    ax.plot(history.history['val_' + metric])\n",
    "    ax.set_ylabel(metric)\n",
    "    ax2=ax.twinx()\n",
    "    ax2.plot(history.history['loss'], c=\"red\")\n",
    "    ax2.plot(history.history['val_loss'], c=\"green\")\n",
    "    ax2.set_ylabel(\"loss\")\n",
    "    plt.title('model accuracy')\n",
    "    #plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train ' + metric, 'val ' + metric, 'train loss', 'val loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss_mae(history, '...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn_dl_python] *",
   "language": "python",
   "name": "conda-env-nn_dl_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
