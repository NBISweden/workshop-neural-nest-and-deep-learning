{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "# Exercise Session annBuilding blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "\n",
    "### Recall the  training algorithm (Gradient descent) for the ANN\n",
    " 1. Initialize weights and biases randomly $\\sim N(0, \\sigma^2)$\n",
    " 2. Loop for $M$ epochs or until convergence:\n",
    "     - _Forward Pass_: Compute the values of loss function, $L(w,b|x)$ and intermediate varibles using the current values of $w$ and $b$.\n",
    "     - _Backward Pass_: For each weight $w_{i,j}$ and each bias $b_j$ :\n",
    "         1. Compute partial derivatives (gradients)\n",
    "         2. Update weights and biases\n",
    " 3. Return final weights and biases\n",
    "\n",
    "In this exercise we will look at a single iteration of the Gradient descent algorithm         \n",
    "\n",
    "### Gradient descents is about derivatives\n",
    "\n",
    "- There's a lot of derivatives in an ANN\n",
    "- *Back-propagation* allows us to compute them efficiently\n",
    "\n",
    "### Back-propagation (BP) is \n",
    "\n",
    "- a Dynamic Programming algorithm for Gradient Descent in ANNs\n",
    "- performed in each iteration/epoch\n",
    "\n",
    "\n",
    "### BP builds on the _Chain rule of differentiation_\n",
    "\n",
    "Let's get a reminder of \n",
    "\n",
    "1. Derivatives, and\n",
    "2. The chain rule\n",
    "\n",
    "*(Note: Differentiation means \"taking the derivative\")*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected basic derivative rules\n",
    "\n",
    "First, we neeed a reminder of some basic derivative rules\n",
    "\n",
    "(Here, $a$ is a positive or negative constants , $x$ is the variable to be differentiated and $f(x)$ and $g(x)$ are two functions of $x$.)\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{da}{dx} =& 0 &\\quad\\textrm{the derivative of a constant is zero}\\\\\n",
    "\\frac{dx^a}{dx} =& ax^{a-1} &\\quad\\textrm{multiply by the exponent and then reduce the exponent by 1}\\\\\n",
    "\\frac{dax}{dx} =& a &\\quad\\textrm{special case of above}\\\\\n",
    "\\frac{de^x}{dx} =& e^x &\\quad\\textrm{the derivative of the exponential funciton is itself}\\\\\n",
    "\\frac{de^{-x}}{dx} =& -e^{-x}&\\quad\\textrm{as above, with a negative exponent}\\\\\n",
    "\\frac{d\\left(f(x)+g(x)\\right)}{dx} =& \\frac{df(x)}{dx} + \\frac{dg(x)}{dx} &\\quad\\textrm{derivative of a sum is the sum of the derivative of its terms}\\\\\n",
    "\\frac{d\\left(f(x)-g(x)\\right)}{dx} =& \\frac{df(x)}{dx} - \\frac{dg(x)}{dx} &\\quad\\textrm{special case of above}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain rule of derivation\n",
    "### A reminder \n",
    "\n",
    "\n",
    "The chain rule simplifies derivation of complex functions and states that\n",
    "\n",
    "$$\\frac{d f(g(x))}{dx} = \\frac{df(g(x))}{dg(x)} \\times \\frac{dg(x)}{d x} $$\n",
    "\n",
    "A complex function can be formulated as a function $f()$ of a function $g()$ of $x$ -- what does this mean? Maybe it is easier to explain this by an example:\n",
    "\n",
    "Consider the complex function $f\\left(g(x)\\right) = \\frac{1}{2}(a-x)^2$, where $g(x) = a-x$ and the function $f(g(x)) = \\frac{1}{2}g(x)^2 = \\frac{1}{2}(a-x)^2$.\n",
    "\n",
    "\n",
    "It is often convenient to simplify notation by introducing a help variable, e.g., $t$, for $g(x)$. \n",
    "\n",
    "\n",
    "\n",
    "$$\\textrm{Let $t=g(x)$, then $f(g(x))=f(t)$}$$\n",
    "\n",
    "...and the re-express the derivative in terms of the help variable:\n",
    "\n",
    "$$\\frac{d f(g(x))}{dx} =\\frac{d f(t)}{dx} = \\frac{df(t)}{dt} \\times \\frac{dt}{dx}$$\n",
    "\n",
    "The result is often easier to solve... but let's look at some examples to make it less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### An example\n",
    "\n",
    "The derivative of half the squared difference, i.e., our example function above:\n",
    "\n",
    "\\begin{eqnarray}\n",
    "f(g(x)) =\\frac{1}{2}(b-x)^2 &&\\\\\n",
    "t = g(x) = b-x\\quad &&\\quad\\textrm{ Introduce help variable, }t\\\\\n",
    "f(t) = \\frac{1}{2}t^2 = \\frac{t^2}{2} &&\\quad  \\textrm{ and re-express}\n",
    "\\end{eqnarray}\n",
    "\n",
    "##### Differentiate\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\frac{d f(g(x))}{dx} = \\frac{df(t)}{dx} = &\\frac{d f(t)}{dt}\\times\\frac{d t}{dx} &\\quad\\textrm{express with help variable and use the chain rule...}\\\\\n",
    "= & \\frac{d f(t)}{dt}\\times\\frac{d g(x)}{dx} &\\quad\\textrm{to split into two derivative factors}\\\\\n",
    "= & \\frac{d \\frac{t^2}{2}}{dt}\\times\\frac{d (b-x)}{dx} &\\quad\\textrm{express 2nd factor in terms of $x$}\\\\\n",
    "= & \\frac{2t}{2} \\times -1 = -t &\\quad\\textrm{solve derivatives}\\\\\n",
    "= & -(b-x) &\\quad\\textrm{express $t$ in terms of $x$}\\\\\n",
    "= & x-b &\\quad\\textrm{and simplify}\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### Another example\n",
    "\n",
    "The derivative of the sigmoid function:\n",
    "\n",
    "Use the chain rule and a help variable $t$:\n",
    "\n",
    "$$\\begin{eqnarray*}\n",
    "\\sigma(x) = f(g(x)) &=& \\frac{1}{1+e^{-x}}\\\\\n",
    "\\\\\n",
    "t &=& g(x) = 1+e^{-x}\\\\\n",
    "\\\\\n",
    "f(t) &=& \\frac{1}{t} = t ^{-1}\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Differentiate:\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{d\\sigma(x)}{d x} = \\frac{df(t)}{dx}\n",
    "&=& \\frac{d f(t)}{d t} \\quad\\times\\quad \\frac{d t}{d x}\\\\\n",
    "&=& \\frac{d t^{-1}}{d t} \\quad\\times\\quad \\frac{d t}{d x}\\\\\n",
    "&=& \\frac{d t^{-1}}{d t} \\quad\\times\\quad \\frac{d \\left(1+e^{-x}\\right)}{d x}\\\\\n",
    "&=& -t^{-2} \\quad\\times\\quad -e^{-x}\\\\\n",
    "&=& \\frac{1}{\\left(1+e^{-x}\\right)^{2}} \\times e^{-x}\\\\\n",
    "&=& \\frac{1}{\\left(1+e^{-x}\\right)} \\frac{e^{-x}}{\\left(1+e^{-x}\\right)}\\\\\n",
    "&=& \\frac{1}{1+e^{-x}}\\quad \\left(1-\\frac{1}{1+e^{-x}}\\right)\\\\\\\\\n",
    "&=& \\sigma(x)\\left(1-\\sigma(x)\\right)\n",
    "\\end{eqnarray*}\n",
    "\n",
    "\n",
    "In second last line, we used the fact that\n",
    "$$1 - \\frac{1}{1+e^{-x}} = \\frac{1+e^{-x}}{1+e^{-x}}- \\frac{1}{1+e^{-x}} = \\frac{1+e^{-x} - 1}{1+e^{-x}} = \\frac{e^{-x}}{1+e^{-x}}$$\n",
    "and then made it a neat expression in terms of $\\sigma(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### NB! The chain rule works just as well on partial derivatives\n",
    "\n",
    "$$\\frac{\\partial f(g(x))}{\\partial x} = \\frac{\\partial f(g(x))}{\\partial g(x)} \\times \\frac{\\partial g(x)}{\\partial x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Back propagation goal\n",
    "\n",
    "Compute the partial derivative of the cost function $L(b,w|x)$ with respect to each parameter $v$ in  $w$ and $b$, i.e.,\n",
    "\n",
    "$$\\frac{\\partial L(b,w|x)}{\\partial v},\\quad v \\in {w, b}$$\n",
    "\n",
    "## Back propagation strategy\n",
    "\n",
    "Use chain rule to split $\\frac{\\partial L(b,w|x)}{\\partial v}$ on the $a_j$s and $z_j$s of each layer, going from right to left.\n",
    "\n",
    "Then compute the partial derivatives and use their products to obtain each relevant $\\frac{\\partial L(b,w|x)}{\\partial v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aim of exercise\n",
    "\n",
    "Perform a forward pass and a backward pass on the two-neuron ffANN in the figure below to compute the gradient $\\frac{\\partial L(b,w|x)}{\\partial w_1}$ and use this to compute and updated weight $w'_1$.\n",
    "\n",
    "Don't worry! We will guide you through this, provide some template code and help fill in the values of the intermediate expression in a a Forward pass table and and Backward pass table, respectively. Feel free to look at the hidden `Solution`s and `Code help`s if it gets too hard.\n",
    "\n",
    "<img src=\"./assets/figExercise.png\" alt=\"exercise ANN\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations\n",
    "\n",
    "Start by downloading the Jupyter notebook version of this exercise -- your _workbook_ for the exercise to your _nndl_ folder:\n",
    "\n",
    "```\n",
    "wget https://raw.githubusercontent.com/NBISweden/workshop-neural-nets-and-deep-learning/master/session_annBuildingBlocks/exercise_back_prop.ipynb\n",
    "```\n",
    "\n",
    "You also need to download a helper python file to the same folder:\n",
    "\n",
    "```\n",
    "wget https://raw.githubusercontent.com/NBISweden/workshop-neural-nets-and-deep-learning/master/session_annBuildingBlocks/exercise_back_prop_helper.py\n",
    "```\n",
    "\n",
    "Open the downloaded  .ipynb file (`exercise_back_prop.ipynb`) in your Jupyter notebook browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. Forward pass\n",
    "\n",
    "Let's start by performing the forward pass of the ANN.\n",
    "\n",
    "We will start by creating variables to hold the values of the intermediate and final expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "#sys.path.append(os.path.abspath('assets'))\n",
    "from exercise_back_prop_helper import *\n",
    "\n",
    "# Known variables\n",
    "# Initialize variables to values in figure\n",
    "x = 0.05\n",
    "y = 0.01\n",
    "w1 = 0.1\n",
    "b1 = -0.1\n",
    "w2 = 0.3\n",
    "b2 = 0.3\n",
    "\n",
    "# Unknown variables to be computed\n",
    "i1 = \"\"\n",
    "z1 = \"\"\n",
    "a1 = \"\"\n",
    "z2 = \"\"\n",
    "a2 = \"\"\n",
    "haty = \"\"\n",
    "L = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the table cell below to display table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c3999_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c3999_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c3999_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$x$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$y$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$w_1$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$b_1$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$i_1$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$z_1$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$a_1$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$w_2$</th>\n",
       "      <th class=\"col_heading level0 col8\" >$b_2$</th>\n",
       "      <th class=\"col_heading level0 col9\" >$z_2$</th>\n",
       "      <th class=\"col_heading level0 col10\" >$a_2$</th>\n",
       "      <th class=\"col_heading level0 col11\" >$\\hat{y}$</th>\n",
       "      <th class=\"col_heading level0 col12\" >$L(w,b|x)$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c3999_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_c3999_row0_col1\" class=\"data row0 col1\" >0.01</td>\n",
       "      <td id=\"T_c3999_row0_col2\" class=\"data row0 col2\" >0.1</td>\n",
       "      <td id=\"T_c3999_row0_col3\" class=\"data row0 col3\" >-0.1</td>\n",
       "      <td id=\"T_c3999_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_c3999_row0_col5\" class=\"data row0 col5\" ></td>\n",
       "      <td id=\"T_c3999_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_c3999_row0_col7\" class=\"data row0 col7\" >0.3</td>\n",
       "      <td id=\"T_c3999_row0_col8\" class=\"data row0 col8\" >0.3</td>\n",
       "      <td id=\"T_c3999_row0_col9\" class=\"data row0 col9\" ></td>\n",
       "      <td id=\"T_c3999_row0_col10\" class=\"data row0 col10\" ></td>\n",
       "      <td id=\"T_c3999_row0_col11\" class=\"data row0 col11\" ></td>\n",
       "      <td id=\"T_c3999_row0_col12\" class=\"data row0 col12\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7ba696590>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable1(x, y, w1, b1, w2, b2, i1, z1, a1, z2, a2, haty,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "source": [
    "### Path of intermediate expressions\n",
    "\n",
    "First, notice that $i_1 = x$ and $\\hat{y} = a_2$.\n",
    "\n",
    "The path of intermediate expressions from $x$ to $L(b,w|x)$ is:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "z_1 &=&  w_1 i_1 + b_1\\\\\n",
    "a_1 &=& \\sigma(z_1) = \\frac{1}{1+e^{-z_1}}\\\\\n",
    "z_2 &=&  w_2 a_{1} + b_2\\\\\n",
    "a_2 &=& \\sigma(z_2) = \\frac{1}{1+e^{-z_2}}\\\\\n",
    "L(w,b|x) &=& \\frac{1}{2}\\left(y-\\hat{y}\\right)^2 = \\frac{1}{2}\\left(y-a_2\\right)^2\n",
    "\\end{eqnarray}$\n",
    "\n",
    "- Try to update the corresponding variables in the code cell below and see if you get the same table values as below\n",
    "    - example: `z1 = w1 * i1 +b1` (remember to set `i1` first)\n",
    "    - *hint!*: to compute $\\sigma(z)$, use, e.g.\n",
    "    ```\n",
    "    import tensorflow as tf\n",
    "    tf.sigmoid(z).numpy()\n",
    "    ``` \n",
    "    - As a last resort you can click the *Code help* below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary> Code help </summary>\n",
    "    \n",
    "```\n",
    "import tensorflow as tf\n",
    "i1 = x\n",
    "z1 = w1 * i1 +b1\n",
    "a1 = tf.sigmoid(z1).numpy()\n",
    "z2 = w2 * a1 + b2\n",
    "a2 = tf.sigmoid(z2).numpy()\n",
    "haty=a2\n",
    "L = (y-haty)/2\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute these variables\n",
    "import tensorflow as tf\n",
    "i1 = \"\"\n",
    "z1 = \"\"\n",
    "a1 = \"\"\n",
    "z2 = \"\"\n",
    "a2 = \"\"\n",
    "haty = \"\"\n",
    "L = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "center",
    "remove_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 14:03:49.240255: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-20 14:03:49.240583: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# This code should be hidden\n",
    "import tensorflow as tf\n",
    "i1 = x\n",
    "z1 = w1 * i1 +b1\n",
    "a1 = tf.math.sigmoid(z1)\n",
    "z2 = w2 * a1 + b2\n",
    "a2 = tf.math.sigmoid(z2)\n",
    "haty=a2\n",
    "L = (y-haty)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide_input": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_97f6e_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_97f6e_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_97f6e_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$x$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$y$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$w_1$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$b_1$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$i_1$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$z_1$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$a_1$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$w_2$</th>\n",
       "      <th class=\"col_heading level0 col8\" >$b_2$</th>\n",
       "      <th class=\"col_heading level0 col9\" >$z_2$</th>\n",
       "      <th class=\"col_heading level0 col10\" >$a_2$</th>\n",
       "      <th class=\"col_heading level0 col11\" >$\\hat{y}$</th>\n",
       "      <th class=\"col_heading level0 col12\" >$L(w,b|x)$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_97f6e_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_97f6e_row0_col1\" class=\"data row0 col1\" >0.01</td>\n",
       "      <td id=\"T_97f6e_row0_col2\" class=\"data row0 col2\" >0.1</td>\n",
       "      <td id=\"T_97f6e_row0_col3\" class=\"data row0 col3\" >-0.1</td>\n",
       "      <td id=\"T_97f6e_row0_col4\" class=\"data row0 col4\" >0.05</td>\n",
       "      <td id=\"T_97f6e_row0_col5\" class=\"data row0 col5\" >-0.095</td>\n",
       "      <td id=\"T_97f6e_row0_col6\" class=\"data row0 col6\" >0.476</td>\n",
       "      <td id=\"T_97f6e_row0_col7\" class=\"data row0 col7\" >0.3</td>\n",
       "      <td id=\"T_97f6e_row0_col8\" class=\"data row0 col8\" >0.3</td>\n",
       "      <td id=\"T_97f6e_row0_col9\" class=\"data row0 col9\" >0.443</td>\n",
       "      <td id=\"T_97f6e_row0_col10\" class=\"data row0 col10\" >0.609</td>\n",
       "      <td id=\"T_97f6e_row0_col11\" class=\"data row0 col11\" >0.609</td>\n",
       "      <td id=\"T_97f6e_row0_col12\" class=\"data row0 col12\" >   -0.299   </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7ba80cad0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable1(x, y, w1, b1, w2, b2, i1, z1, a1, z2, a2, haty,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Example: Backward pass to compute $\\frac{\\partial L(w,b|x)}{\\partial w_2}$\n",
    "\n",
    "### 1. Identify relevant path (from forward path)\n",
    "\n",
    "Here, we focus on the path from $w_2$ to $L(w,b|x)$, i.e., the second neuron \n",
    "\n",
    "$\\begin{eqnarray}\n",
    "z_2 &=&  w_2 a_{1} + b_2\\\\\n",
    "a_2 &=& \\sigma(z_2) = \\frac{1}{1+e^{-z_2}}\\\\\n",
    "L(w,b|x) &=& \\frac{1}{2}\\left(y-\\hat{y}\\right)^2 = \\frac{1}{2}\\left(y-a_2\\right)^2\n",
    "\\end{eqnarray}$\n",
    "\n",
    "### 2. Apply chain rule\n",
    "\n",
    "We use the chain rule to split $\\frac{\\partial L(w,b|x)}{\\partial w_2}$ on $a_2$ and $z_2$, in turn, and do it  backwards along the path, i.e., from right to left in the figure above.\n",
    "\n",
    "#### First split on $a_2$:\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial L(w,b|x)}{\\partial w_2} &=& \\frac{\\partial a_2}{\\partial w_2}\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "#### Then split first factor on $z_2$:\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial L(w,b|x)}{\\partial w_2} &=&  \\frac{\\partial z_2}{\\partial w_2}\\times \\frac{\\partial a_2}{\\partial z_2} \\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compute individual partial derivatives\n",
    "\n",
    "The resulting partial derivatives are easier to compute. In fact you know how to compute some of them already:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "&=&  \\frac{\\partial \\frac{1}{2}(y-a_2)^2}{\\partial a_2}\n",
    "\\end{eqnarray}$  \n",
    "This is a derivative we just learnt above (with $x$ substituted for $a_1$ and $b$ for $y$),  \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "&=&  a_2-y\n",
    "\\end{eqnarray}$  \n",
    "Now, we just need to fill in the values of $y$ and $a_2$ from our Forward pass table  \n",
    "$\\begin{eqnarray}\\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "&=&  0.609 - 0.01 = 0.599\n",
    "\\end{eqnarray}$  \n",
    "<br>\n",
    " \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial a_2}{\\partial z_2} \n",
    "&=&  \\frac{\\partial \\sigma(z_2)}{\\partial z_2}\\\\\n",
    "\\end{eqnarray}$  \n",
    "Again, a derivative we learned above (with $x$ substituted for $z_2$).  \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial a_2}{\\partial z_2} \n",
    "&=&  \\sigma(z_2)\\left(1-\\sigma(z_2)\\right) = a_2(1-a_2)\\\\\n",
    "\\end{eqnarray}$\n",
    "Filling in the values of $a_2$ from our Forward pass table, gives  \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial a_2}{\\partial z_2} \n",
    "&=&  0.609\\times(1-0.609) = 0.238\n",
    "\\end{eqnarray}$  \n",
    "<br>\n",
    "\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_2}{\\partial w_2} &=&  \\frac{\\partial w_2 a_1+b_2}{\\partial w_2} \\\\\n",
    "\\end{eqnarray}$  \n",
    "which is a is a derivative of a sum that can be solved with the standard derivative rules above,  \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_2}{\\partial w_2} &=&  a_1 \\\\\n",
    "\\end{eqnarray}$ \n",
    "Filling in the values of and $a_1$ from our Forward pass table, gives us  \n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_2}{\\partial w_2} &=&  0.476 \\\\\n",
    "\\end{eqnarray}$ \n",
    "\n",
    "\n",
    "\n",
    "### 4. Compute the requested (full) partial derivative\n",
    "\n",
    "Finally, we get the value of $\\frac{\\partial L(w,b|x)}{\\partial w_1}$ by simply multiplying the three partial derivatives.\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial L(w,b|x)}{\\partial w_2} &=&  \\frac{\\partial z_2}{\\partial w_2}\\times \\frac{\\partial a_2}{\\partial z_2} \\times \\frac{\\partial L(w,b|x)}{\\partial a_2}\\\\\n",
    "&=& 0.476 \\times 0.238 \\times 0.599 = 0.0577\n",
    "\\end{eqnarray}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Compute the updated weight $w'_2$\n",
    "\n",
    "Recall that an updated weight $w'$ is computed as\n",
    "\n",
    "$$w' = w - \\eta \\frac{\\partial L(w,b|x)}{\\partial w_2}$$\n",
    "\n",
    "Let's use an $\\eta = 0.05$\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "w'_2 &=& w_2 - \\eta \\times \\frac{\\partial L(w,b|x)}{\\partial w_2} \n",
    "&=& 0.3 - 0.05\\times 0.0577 =0.297\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program it!\n",
    "Let's perform the computation of the variables above as python variable and summarize these variables in a table. We use this simple scheme for naming the variables:\n",
    "\n",
    "`dLda2` = $\\frac{\\partial L(b,w|x)}{\\partial a_2}$\n",
    "\n",
    "`da2dz2` = $\\frac{\\partial a_2}{\\partial z_2}$\n",
    "\n",
    "etc.\n",
    "\n",
    "The variables will then be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLda2 = a2 - y\n",
    "da2dz2 = a2 * (1-a2)\n",
    "dz2dw2 = a1\n",
    "dLdw2 = dLda2 * da2dz2 * dz2dw2\n",
    "eta = 0.05\n",
    "w2new = w2 - dLdw2 * eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the table cell below to display table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e9db7_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e9db7_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e9db7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$\\frac{\\partial z_2}{\\partial w_2}$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(b,w|x)}{\\partial a_2}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial L(b,w|a)}{\\partial w_2}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$w'_2$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e9db7_row0_col0\" class=\"data row0 col0\" >0.476</td>\n",
       "      <td id=\"T_e9db7_row0_col1\" class=\"data row0 col1\" >0.238</td>\n",
       "      <td id=\"T_e9db7_row0_col2\" class=\"data row0 col2\" >   0.599    </td>\n",
       "      <td id=\"T_e9db7_row0_col3\" class=\"data row0 col3\" >   0.0679   </td>\n",
       "      <td id=\"T_e9db7_row0_col4\" class=\"data row0 col4\" >0.05</td>\n",
       "      <td id=\"T_e9db7_row0_col5\" class=\"data row0 col5\" >0.297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c106be50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable2(dLda2, da2dz2, dz2dw2, dLdw2, eta, w2new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about the other layers?\n",
    "\n",
    "To compute, e.g., $\\frac{\\partial L(w,b|x)}{\\partial w_1}$, we will need to apply the chain rule to split on to $a_2$, $a_z$, $a_1$, $z_1$, etc...\n",
    "\n",
    "... in fact, that's what you will do now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Backward pass\n",
    "\n",
    "Perform a backward pass to update the value of $w_1$, that is, use the chain rule to split $\\frac{\\partial L(b,w|x)}{\\partial w_1}$, create variables for the intermediate expressions and compute their values, values compute the value of $\\frac{\\partial L(b,w|x)}{\\partial w_1}$, and compute $w'_2$ (i.e., the updated value of $w_2$)\n",
    "\n",
    "Let's first print out the ANN and the table with values from the forward pass again, just to have them handy \n",
    "\n",
    "<img src=\"./assets/figExercise.png\" alt=\"exercise ANN\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_style": "center",
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_361c7_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_361c7_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_361c7_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$x$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$y$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$w_1$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$b_1$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$i_1$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$z_1$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$a_1$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$w_2$</th>\n",
       "      <th class=\"col_heading level0 col8\" >$b_2$</th>\n",
       "      <th class=\"col_heading level0 col9\" >$z_2$</th>\n",
       "      <th class=\"col_heading level0 col10\" >$a_2$</th>\n",
       "      <th class=\"col_heading level0 col11\" >$\\hat{y}$</th>\n",
       "      <th class=\"col_heading level0 col12\" >$L(w,b|x)$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_361c7_row0_col0\" class=\"data row0 col0\" >5</td>\n",
       "      <td id=\"T_361c7_row0_col1\" class=\"data row0 col1\" >0.01</td>\n",
       "      <td id=\"T_361c7_row0_col2\" class=\"data row0 col2\" >0.1</td>\n",
       "      <td id=\"T_361c7_row0_col3\" class=\"data row0 col3\" >-0.1</td>\n",
       "      <td id=\"T_361c7_row0_col4\" class=\"data row0 col4\" >0.05</td>\n",
       "      <td id=\"T_361c7_row0_col5\" class=\"data row0 col5\" >-0.095</td>\n",
       "      <td id=\"T_361c7_row0_col6\" class=\"data row0 col6\" >0.476</td>\n",
       "      <td id=\"T_361c7_row0_col7\" class=\"data row0 col7\" >0.3</td>\n",
       "      <td id=\"T_361c7_row0_col8\" class=\"data row0 col8\" >0.3</td>\n",
       "      <td id=\"T_361c7_row0_col9\" class=\"data row0 col9\" >0.443</td>\n",
       "      <td id=\"T_361c7_row0_col10\" class=\"data row0 col10\" >0.609</td>\n",
       "      <td id=\"T_361c7_row0_col11\" class=\"data row0 col11\" >0.609</td>\n",
       "      <td id=\"T_361c7_row0_col12\" class=\"data row0 col12\" >   -0.299   </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7bca5d9d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable1(x, y, w1, b1, w2, b2, i1, z1, a1, z2, a2, haty,L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The relevant path\n",
    "\n",
    "The path from $w_1$ to $L(w,b|x)$ is\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "z_1 &=&  w_1 i_1 + b_1\\\\\n",
    "a_1 &=& \\sigma(z_1) = \\frac{1}{1+e^{-z_1}}\\\\\n",
    "z_2 &=&  w_2 a_{1} + b_2\\\\\n",
    "a_2 &=& \\sigma(z_2) = \\frac{1}{1+e^{-z_2}}\\\\\n",
    "L(w,b|x) &=& \\frac{1}{2}\\left(y-\\hat{y}\\right)^2 = \\frac{1}{2}\\left(y-a_2\\right)^2\n",
    "\\end{eqnarray}$\n",
    "\n",
    "### 2. Apply the chain  rule\n",
    "\n",
    "Appying the chain rule on $a$'s and $z$'s of the layers backwards (from right to left in the figure) gives (green color indicates which expression to split in the next row):\n",
    "\n",
    "<!--\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial L(w,b|x)}{\\partial w_1} &=&  \\frac{\\partial a_2}{\\partial w_1}\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial a_2}{\\partial w_1} &=&  \\frac{\\partial z_2}{\\partial w_1}\\times \\frac{\\partial a_2}{\\partial z_2} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial z_2}{\\partial w_1} &=&  \\frac{\\partial a_1}{\\partial w_1}\\times \\frac{\\partial z_2}{\\partial a_1} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial a_1}{\\partial w_1} &=&  \\frac{\\partial z_1}{\\partial w_1}\\times \\frac{\\partial a_1}{\\partial z_1} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial z_1}{\\partial w_1x} &=&  \\frac{\\partial w_1 \\times i_1 + b_1}{\\partial w_1}\n",
    "\\end{eqnarray}$\n",
    "-->\n",
    "\n",
    "\n",
    "$\\hspace{1cm}\\begin{eqnarray} \n",
    "\\frac{\\partial L(w,b|x)}{\\partial w_1} \n",
    "&=&  \n",
    "\\color{green}{\\frac{\\partial a_2}{\\partial w_1}} \n",
    "\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \\\\\n",
    "%\\frac{\\partial L(w,b|x)}{\\partial w_1} \n",
    "&=&  \n",
    "\\color{green}{\\frac{\\partial z_2}{\\partial w_1}}\n",
    "\\times \\frac{\\partial a_2}{\\partial z_2} \n",
    "\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \\\\\n",
    "%\\frac{\\partial L(w,b|x)}{\\partial w_1} \n",
    "&=&  \n",
    "\\color{green}{\\frac{\\partial a_1}{\\partial w_1}}\n",
    "\\times \\frac{\\partial z_2}{\\partial a_1}\n",
    "\\times \\frac{\\partial a_2}{\\partial z_2} \n",
    "\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \\\\\n",
    "%\\frac{\\partial L(w,b|x)}{\\partial w_1} \n",
    "&=&  \n",
    "\\color{green}{\\frac{\\partial z_1}{\\partial w_1}}\n",
    "\\times \\frac{\\partial a_1}{\\partial z_1} \n",
    "\\times \\frac{\\partial z_2}{\\partial a_1}\n",
    "\\times \\frac{\\partial a_2}{\\partial z_2} \n",
    "\\times \\frac{\\partial L(w,b|x)}{\\partial a_2} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "We see that we have already computed the last of these partial derivatives, namely $\\frac{\\partial a_2}{\\partial z_2}$ and $\\frac{\\partial L(w,b|x)}{\\partial a_2}$. This is a very nice feature of back-propagation:  \n",
    "$\\quad$_If we have computed the values of partial derivatives for a layer, we can **reuse** these expressions in the preceeding layer._\n",
    "\n",
    "(In computer science terms, back propagation is a _dynamic programming_ algorithm, that is, it is works in an iterative fashion, tabulates the values from one iteration (=layer), and reuses them in the next iteration in the algorithm (i.e., the previous layer, since we go backwards).)\n",
    "\n",
    "Let's set up python variables for these intermediate expressions (reuse the ones already computed!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Unknown variables to compute in Back-propagation\n",
    "\n",
    "#dLda2 = \"\" # Already computed, reuse\n",
    "#da2dz2 = \"\" # Already computed, reuse!\n",
    "dz2da1 = \"\"\n",
    "da1dz1 = \"\"\n",
    "dz1dw1 = \"\"\n",
    "dLdw1 = \"\"\n",
    "#eta = \"\" # Already computed, reuse\n",
    "w1new = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6ef1b_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6ef1b_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6ef1b_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_6ef1b_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_6ef1b_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_6ef1b_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_6ef1b_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_6ef1b_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_6ef1b_row0_col5\" class=\"data row0 col5\" ></td>\n",
       "      <td id=\"T_6ef1b_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_6ef1b_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7ba80ced0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### 3. Solve partial derivatives 1\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_2}{\\partial a_1} \n",
    "&=&  \\frac{\\partial w_2 a_1 +b_1}{\\partial a_1} \\\\\n",
    "&=& ?\n",
    "\\end{eqnarray}$\n",
    "\n",
    "(Write the answer on paper -- you don't have to type the latex code)\n",
    "***\n",
    "<details>\n",
    "    <summary> Solution </summary>\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_2}{\\partial a_1} \n",
    "&=&  \\frac{\\partial w_2 a_1 +b_1}{\\partial a_1} \\\\\n",
    "&=& w_2\n",
    "\\end{eqnarray}$\n",
    "</details>\n",
    "\n",
    "***\n",
    "\n",
    "- Then fill in the corresponding code below and see if you get the same table values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "hide_input": true
   },
   "source": [
    "<details>\n",
    "<summary> Code help </summary>\n",
    "\n",
    "```\n",
    "dz2da1 = w2\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_style": "center",
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute this variable\n",
    "dz2da1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "center",
    "hide_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell should be hidden\n",
    "dz2da1 = w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f37db_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f37db_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f37db_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f37db_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_f37db_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_f37db_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_f37db_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_f37db_row0_col4\" class=\"data row0 col4\" ></td>\n",
       "      <td id=\"T_f37db_row0_col5\" class=\"data row0 col5\" >0.3</td>\n",
       "      <td id=\"T_f37db_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_f37db_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c1088190>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### 3. Solve partial derivatives 2\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial a_1}{\\partial z_2} \n",
    "&=&  \\frac{\\partial \\sigma(z_2)}{\\partial z_2} \\\\\n",
    "&=& \\sigma(z_2)\\left(1-\\sigma(z_2)\\right)\\\\\n",
    "&=& ?\n",
    "\\end{eqnarray}$\n",
    "\n",
    "***\n",
    "<details>\n",
    "    <summary> Solution </summary>\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial a_1}{\\partial z_2} \n",
    "&=&  \\frac{\\partial \\sigma(z_2)}{\\partial z_2} \\\\\n",
    "&=& \\sigma(z_2)\\left(1-\\sigma(z_2)\\right)\\\\\n",
    "&=& a_1\\left(1-a_1\\right)\n",
    "\\end{eqnarray}$\n",
    "\n",
    "</details>\n",
    "\n",
    "***\n",
    "\n",
    "- Then fill in the corresponding code below and see if you get the same table values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Code help </summary>\n",
    "```\n",
    "da1dz1 = a1*(1-a1)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute this variable\n",
    "\n",
    "da1dz1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell should be hidden\n",
    "da1dz1 = a1*(1-a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_style": "center",
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a8da1_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a8da1_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a8da1_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a8da1_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_a8da1_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_a8da1_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_a8da1_row0_col3\" class=\"data row0 col3\" ></td>\n",
       "      <td id=\"T_a8da1_row0_col4\" class=\"data row0 col4\" >0.249</td>\n",
       "      <td id=\"T_a8da1_row0_col5\" class=\"data row0 col5\" >0.3</td>\n",
       "      <td id=\"T_a8da1_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_a8da1_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c1031550>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### 3. Solve partial derivatives  3\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_1}{\\partial w_1} \n",
    "&=&  \\frac{\\partial w_1 i_1 + b_1}{\\partial w_1}\\\\\n",
    "&=& ?\n",
    "\\end{eqnarray}$\n",
    "\n",
    "***\n",
    "<details>\n",
    "    <summary> Solution </summary>\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial z_1}{\\partial w_1} \n",
    "&=&  \\frac{\\partial w_1 i_1 + b_1}{\\partial w_1}\\\\\n",
    "&=& i_1\n",
    "\\end{eqnarray}$\n",
    "\n",
    "\n",
    "</details>\n",
    "\n",
    "***\n",
    "\n",
    "- Then fill in the corresponding code below and see if you get the same table values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Code help </summary>\n",
    "    \n",
    "```\n",
    "dz1dw1 = i1\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute this variable\n",
    "\n",
    "dz1dw1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell should be hidden\n",
    "dz1dw1 = i1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5c32f_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5c32f_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5c32f_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5c32f_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_5c32f_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_5c32f_row0_col2\" class=\"data row0 col2\" ></td>\n",
       "      <td id=\"T_5c32f_row0_col3\" class=\"data row0 col3\" >0.05</td>\n",
       "      <td id=\"T_5c32f_row0_col4\" class=\"data row0 col4\" >0.249</td>\n",
       "      <td id=\"T_5c32f_row0_col5\" class=\"data row0 col5\" >0.3</td>\n",
       "      <td id=\"T_5c32f_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_5c32f_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c1072710>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### 4. Compute the requested (full) partial derivative\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial w_1} \n",
    "&=&  \n",
    "\\frac{\\partial z_1}{\\partial w_1} \n",
    "\\times\n",
    "\\frac{\\partial a_1}{\\partial z_1} \n",
    "\\times\n",
    "\\frac{\\partial z_2}{\\partial a_1} \n",
    "\\times\n",
    "\\frac{\\partial a_2}{\\partial z_2} \n",
    "\\times\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_2} \n",
    "\\end{eqnarray}$\n",
    "\n",
    "- And fill in the corresponding code below and see if you get the same table values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Code help </summary>\n",
    "    \n",
    "```\n",
    "dLdw1 = dz1dw1 * da1dz1 * dz2da1 * da2dz2 * dLda2\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute this variable\n",
    "dLdw1 = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell shopould be hidden\n",
    "dLdw1 = dz1dw1 * da1dz1 * dz2da1 * da2dz2 * dLda2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide_input": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_79032_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_79032_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_79032_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_79032_row0_col0\" class=\"data row0 col0\" ></td>\n",
       "      <td id=\"T_79032_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_79032_row0_col2\" class=\"data row0 col2\" >0.000534</td>\n",
       "      <td id=\"T_79032_row0_col3\" class=\"data row0 col3\" >0.05</td>\n",
       "      <td id=\"T_79032_row0_col4\" class=\"data row0 col4\" >0.249</td>\n",
       "      <td id=\"T_79032_row0_col5\" class=\"data row0 col5\" >0.3</td>\n",
       "      <td id=\"T_79032_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_79032_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c1095810>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "### 5. Update $w_1$\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "w'_1\n",
    "&=&  w_1 - \\eta \\frac{\\partial L(b,wx)}{\\partial w_1}\n",
    "\\end{eqnarray}$\n",
    "\n",
    "- And fill in the corresponding code below and see if you get the same table values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Code help </summary>\n",
    "    \n",
    "```\n",
    "w1new = w1 - eta * dLdw1\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# Replace \"\" with the code to compute this variable\n",
    "\n",
    "w1new = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide_input": true,
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell should be hidden\n",
    "w1new = w1 - eta * dLdw1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a table with these values (execute the table cell to update the table!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9c895_ th {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9c895_ td {\n",
       "  font-size: 18px;\n",
       "  max-width: 2.5cm;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9c895_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"col_heading level0 col0\" >$w'_1$</th>\n",
       "      <th class=\"col_heading level0 col1\" >$\\eta$</th>\n",
       "      <th class=\"col_heading level0 col2\" >$\\frac{\\partial L(w,b|x)}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col3\" >$\\frac{\\partial z_1}{\\partial w_1}$</th>\n",
       "      <th class=\"col_heading level0 col4\" >$\\frac{\\partial a_1}{\\partial z_1}$</th>\n",
       "      <th class=\"col_heading level0 col5\" >$\\frac{\\partial z_2}{\\partial a_1}$</th>\n",
       "      <th class=\"col_heading level0 col6\" >$\\frac{\\partial a_2}{\\partial z_2}$</th>\n",
       "      <th class=\"col_heading level0 col7\" >$\\frac{\\partial L(w,b|x)}{\\partial a_2}$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_9c895_row0_col0\" class=\"data row0 col0\" >0.1</td>\n",
       "      <td id=\"T_9c895_row0_col1\" class=\"data row0 col1\" >0.05</td>\n",
       "      <td id=\"T_9c895_row0_col2\" class=\"data row0 col2\" >0.000534</td>\n",
       "      <td id=\"T_9c895_row0_col3\" class=\"data row0 col3\" >0.05</td>\n",
       "      <td id=\"T_9c895_row0_col4\" class=\"data row0 col4\" >0.249</td>\n",
       "      <td id=\"T_9c895_row0_col5\" class=\"data row0 col5\" >0.3</td>\n",
       "      <td id=\"T_9c895_row0_col6\" class=\"data row0 col6\" >0.238</td>\n",
       "      <td id=\"T_9c895_row0_col7\" class=\"data row0 col7\" >   0.599    </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb7c109b490>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updateTable3(dLda2, da2dz2, dz2da1, da1dz1, dz1dw1, dLdw1, eta, w1new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# What about the bias?\n",
    "\n",
    "The biases $b_1$ and $b_2$ are udpated in very much the same way as the weights:\n",
    "\n",
    "1. Determine the (forward) path from the bias in question, $b_i$, to the loss function $L(b,w|x)$. For $b_2$ this is: \n",
    "$$\\begin{eqnarray}\n",
    "z_2 &=&  w_2 a_{1} + b_2\\\\\n",
    "a_2 &=& \\sigma(z_2) = \\frac{1}{1+e^{-z_2}}\\\\\n",
    "L(w,b|x) &=& \\frac{1}{2}\\left(y-\\hat{y}\\right)^2 = \\frac{1}{2}\\left(y-a_2\\right)^2\n",
    "\\end{eqnarray}$$  \n",
    "(What would it be for $b_1$?)\n",
    "2. Use the chain rule to split the requested partial derivative $\\frac{\\partial L(b,w|x)}{\\partial b_i}$ on the $a_i$s and $z_i$s along this path.\n",
    "3. Solve ther partial derivatives of the split expression and compute their values\n",
    "4. Compute the value of $\\frac{\\partial L(b,w|x)}{\\partial b_i}$ using the partial derivatives of the split expression\n",
    "5. Update the requested bias $b_i$ using $\\eta$ and $\\frac{\\partial L(b,w|x)}{\\partial b_i}$.\n",
    "\n",
    "(_If and only if_ you get time over, you could try to do this for $b_2$ and/or $b_1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# What happens if we have more neurons per layer?\n",
    "<img src=\"./assets/figExercise2.png\" alt=\"Neuron\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we would still use the same general approach, but we get more paths to keep track of.\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "Because there are now two paths to go from $i_1$ to $\\hat{y}_1$ (and similarly from $i_1$ to $\\hat{y}_2$), we need to sum over these ways in the forward pass. This is done when computing $z_1^O$, e.g.:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "&\\cdots&\\\\\n",
    "z_1^O &=& \\color{green}{\\left(\\sum_{j=1}^2 w_{j,1}^O a_j^H\\right) + b_1^O}\\\\\n",
    "\\hat{y}_1 &=& a_1^O = \\sigma(z_1^O)\\\\\n",
    "\\end{eqnarray}$\n",
    "\n",
    "## Backward pass\n",
    "\n",
    "Similarly, there are now two paths to consider when computing $\\frac{\\partial L(b,w|w)}{\\partial w_1^H}$, one through $\\hat{y}_1$ and one  trough $\\hat{y}_2$ (see the ANN figure), and again we need to sum over these. Here it is done at the when splitting $\\frac{\\partial L(b,w|x)}{\\partial w_1^H}$ at $a_1^H$, e.g.;\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial w_{1,1}^H} &=&\n",
    "\\frac{\\partial z_1^H}{\\partial w_{1,1}^H} \n",
    "\\times\n",
    "\\frac{\\partial a_1^H}{\\partial z_1^H} \n",
    "\\times\n",
    "\\color{green}{\\sum_{j=1}^2\n",
    "\\frac{\\partial z_j^O}{\\partial a_1^H}}\n",
    "\\times\n",
    "\\frac{\\partial a_j^O}{\\partial z_j^O} \n",
    "\\times\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_j^H} \n",
    "\\end{eqnarray}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix algebra\n",
    "\n",
    "In fact it turns out that it is beneficial to collect similar variables into vectors and matrices, i.e., gradients, and then use matrix multiplication between these to compute all partial derivatives in one go. \n",
    "\n",
    "However, this would **extra-curricular for this course**, (but a walk-through is provided at the end of the exercise (only in _html_ version) as a challenge only for those who _really loves math_ and _if and only if_ they have time (NB! this will require familiarity with matrix algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## So what does Tensorflow do?\n",
    "\n",
    "Well, it uses matrix multiplication, but adds an additional twist:\n",
    "\n",
    "While it works with gradients, it does this for all training samples at once, so that each gradient for all samples are collected in a multi-dimensional matrix ort a tensor (tensors $\\approx$ \"matrices of any dimension\"). It then uses matrix multiplication on these tensors and perform gradient descent for all samples at the same time.\n",
    "\n",
    "### \"Tensors flows through the network!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Summary -- Back-propagation\n",
    "\n",
    "## Efficient computation of partial derivatives $\\frac{\\partial L(w,b|x)}{\\partial v}, v\\in w\\cup b$\n",
    "\n",
    "+ Chain rule allows computing partial derivatives layer-wise, backwards\n",
    "+ By collecting gradients and weights for layers in *tensors* over all training data, all computations in one epoch can be computed at the same time for all training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## End of the official exercise\n",
    "\n",
    "***\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "*****\n",
    "\n",
    "### Extra-curricular: Walk-through of forward and backward pass of the ANN with more than one neuron per layer\n",
    "\n",
    "NB! This is only for those who really loves math, it requires familiarity with matrix algebra -- not part of the course.\n",
    "\n",
    "We will focus on updating the values of $w^H =\\left(w_{1,1}^H, w_{1,2}^H\\right)$ using $\\frac{\\partial L(b,w|x)}{\\partial w^H}$ and $\\eta=0.05$ in the ANN in the figure below.\n",
    "\n",
    "<img src=\"./assets/figExercise2.png\" alt=\"Neuron\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Forward pass\n",
    "\n",
    "Let's first write up the forward pass as individual variables.\n",
    "\n",
    "Path from weights $w_1^{H}$ and $w_2^{H}$ to $L(b,w|x)$:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "z_1^H &=&  w_{1,1}^H i_{1} + b_1^H\\\\\n",
    "z_2^H &=&  w_{1,2}^H i_{1} + b_2^H\\\\\n",
    "\\\\\n",
    "a_1^H &=& \\sigma(z_1^H)\\\\\n",
    "a_2^H &=& \\sigma(z_2^H)\\\\\n",
    "\\\\\n",
    "z_1^O &=& \\left(\\sum_{j=1}^2 w_{j,1}^O a_j^H\\right) + b_1^O\\\\\n",
    "z_2^O &=& \\left(\\sum_{j=1}^2 w_{j,2}^O a_j^H \\right)+ b_2^O\\\\\n",
    "\\\\\n",
    "a_1^O &=& \\sigma(z_1^O)\\\\\n",
    "a_2^O &=& \\sigma(z_2^O)\\\\\n",
    "\\\\\n",
    "L(b,w|x) &=& \\sum_{j=1}^2 \\frac{1}{2}\\left(y_j-\\hat{y}_j\\right)^2 = \\sum_{j=1}^2 \\frac{1}{2}\\left(y_j-a_j^O\\right)^2\\\\\n",
    "%L(w,b|x)_1 &=& \\frac{1}{2}\\left(y_1-\\hat{y}_1\\right)^2 = \\frac{1}{2}\\left(y_1-a_1^O\\right)^2\\\\\n",
    "%L(w,b|x)_2 &=& \\frac{1}{2}\\left(y_2-\\hat{y}_2\\right)^2 = \\frac{1}{2}\\left(y_2-a_2^O\\right)^2\\\\\n",
    "%\\\\\n",
    "%L(w,b|x) &=& L(w,b|x)_1  +L(w,b|x)_2\n",
    "\\end{eqnarray}$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Now, let's do the forward pass using vectors and matrices.\n",
    "\n",
    "We start with defining vectors/matrices for the known parameters, i.e., $i$, $w^H$, $b^H$, $w^O$ and $b^O$:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "i &=& \n",
    "i_1 \n",
    "\\\\\n",
    "w^H &=& \\left(\n",
    "\\begin{array}{cc}\n",
    "w_{1,1}^H \\\\\n",
    "w_{1,2}^H \n",
    "\\end{array}\n",
    "\\right)\n",
    "\\\\\n",
    "b^H &=& \\left(\n",
    "\\begin{array}{cc}\n",
    "b_1^H \\\\\n",
    "b_2^H\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\\\\n",
    "w^O &=& \\left(\n",
    "\\begin{array}{c}\n",
    "w_{1,1}^O, &\n",
    "w_{2,1}^O \\\\\n",
    "w_{1,2}^O, &\n",
    "w_{2,2}^O \n",
    "\\end{array}\n",
    "\\right)\n",
    "\\\\\n",
    "b^O &=& \\left(\n",
    "\\begin{array}{c}\n",
    "b_1^O \\\\\n",
    "b_2^O \n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{eqnarray}$$  \n",
    "\n",
    "We can now express the unknown variables in terms of matrix multiplications. Let's start with $z^H$\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "z^H &=& \\left(\n",
    "\\begin{array}{c}\n",
    "z_1^H \\\\\n",
    "z_2^H \n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "w^H \\times i +b^H\n",
    "\\end{eqnarray}$$  \n",
    "\n",
    "Let's check that this is correct:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "z^H &=&\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "w_{1,1}^H \\\\\n",
    "w_{1,2}^H\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\times i_1 \n",
    "+ \n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "b_1^H \\\\\n",
    "b_2^H\n",
    "\\end{array}\n",
    "\\right)\\\\\n",
    "&=&\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "w_{1,1}^H i \\\\\n",
    "w_{1,2}^H i\n",
    "\\end{array}\n",
    "\\right)\n",
    "+\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "b_1^H \\\\\n",
    "b_2^H\n",
    "\\end{array}\n",
    "\\right)\\\\\n",
    "&=&\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "w_{1,1}^H i + b_1^H \\\\\n",
    "w_{1,2}^H i + b_2^H\n",
    "\\end{array}\n",
    "\\right)\n",
    "\\end{eqnarray}$$ \n",
    "\n",
    "This seems to be correct. Let's express the other variables as matrix multiplications:\n",
    "\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "a^H &=& \\left(\n",
    "\\begin{array}{c}\n",
    "a_1^H \\\\\n",
    "a_2^H \n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "\\sigma(z^H)\n",
    "\\\\\n",
    "z^O &=& \\left(\n",
    "\\begin{array}{c}\n",
    "z_1^O \\\\\n",
    "z_2^O \n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "w^O \\times a^H + b^O\n",
    "\\\\\n",
    "a^O &=& \\left(\n",
    "\\begin{array}{c}\n",
    "a_1^O \\\\\n",
    "a_2^O \n",
    "\\end{array}\n",
    "\\right)\n",
    "=\n",
    "\\sigma(z^O)\n",
    "\\\\\n",
    "L(b,w|x) &=& \\sum_{j=1}^2 \\frac{1}{2}\\left(y_j-a_j^O\\right)^2\\\\\n",
    "\\end{eqnarray}$$  \n",
    "\n",
    "As an exercise, you can check that the other matrix operations gives the expected result (especially interesting is to see if the summations in $z^O$ becomes right).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward pass\n",
    "\n",
    "Let's do the backward pass for $\\frac{\\partial L(b,w|x)}{\\partial w^H}$.\n",
    "\n",
    "### 1. Path\n",
    "The path is the full pathfrom the forward pass.\n",
    "\n",
    "### 2. Chain rule\n",
    "\n",
    "As before, we use the chain rule to split $\\frac{\\partial L(b,w|x)}{\\partial w^H}$ on the $z$s and $a$s of each layer, but now we do it using vectors and matrices (as before the green marks the expression to split in the next row):\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial w^H} \n",
    "&=& \n",
    "\\color{green}{\n",
    "\\frac{\\partial a^O}{\\partial w^H} \n",
    "}\n",
    "\\times \n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O} \n",
    "\\\\\n",
    "&=& \n",
    "\\color{green}{\n",
    "\\frac{\\partial z^O}{\\partial w^H}\n",
    "}\n",
    "\\times \n",
    "\\frac{\\partial a^O}{\\partial z^O} \n",
    "\\times \n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O} \n",
    "\\\\\n",
    "&=& \n",
    "\\color{green}{\n",
    "\\frac{\\partial a^H}{\\partial w^H}\n",
    "}\n",
    "\\times\n",
    "\\frac{\\partial z^O}{\\partial a^H} \n",
    "\\times \n",
    "\\frac{\\partial a^O}{\\partial z^O} \n",
    "\\times \n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O} \\\\\n",
    "&=& \n",
    "\\frac{\\partial z^H}{\\partial w^H}\n",
    "\\times \n",
    "\\frac{\\partial a^H}{\\partial z^H} \n",
    "\\times \n",
    "\\frac{\\partial z^O}{\\partial a^H} \n",
    "\\times\n",
    "\\frac{\\partial a^O}{\\partial z^O} \n",
    "\\times \n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O}\\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "### 3. Solve partial derivatives\n",
    "\n",
    "Before we move on to expressing the partial derivatives, we need to define some missing matrices, the $y$ matrix and the identity matrix, $I$, which will become handy:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "y &=&\n",
    "\\left(\\begin{array}{c}\n",
    "y_1\\\\\n",
    "y_2\n",
    "\\end{array}\\right)\\\\\n",
    "\\\\\n",
    "% \n",
    "I &=&\n",
    "\\left(\\begin{array}{cc}\n",
    "1, & 0\\\\\n",
    "0, & 1\n",
    "\\end{array}\\right)\\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Now, we start defining the intermediate partial derivative expressions. Let's look at $\\frac{\\partial L(b,w|x)}{\\partial a^O}$ (see below). Since $a^O$ is actually a vector, $\\frac{\\partial L(b,w|x)}{\\partial a^O}$ will also be a vector with the rows in the vector representing the partial derivstive, with respect to $a_1^O$ and $a_2^O$, respectively.\n",
    "Moreover, consider row 1: it contains a summation over the index $j$; however, one of the terms does not contain $a_1^O$ and the derivative of this term is therefore zero. In the end, it turns out that the answer is simply the difference between the $a^=$ vector and the $y$ vector.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O} \n",
    "&=& \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_1^O}\\\\\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_2^O}\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=& \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial \\sum_{j=i}^2 \\frac{1}{2}\\left(y_j-a_j^O\\right)^2}{\\partial a_1^O}\\\\\n",
    "\\frac{\\partial \\sum_{j=i}^2 \\frac{1}{2}\\left(y_j-a_j^O\\right)^2}{\\partial a_2^O}\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=& \n",
    "\\left(\\begin{array}{c}\n",
    "a_1^O - y_1\\\\\n",
    "a_2^O - y_2\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "a^O-y\\\\\n",
    "\\\\\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "If we go on to $\\frac{\\partial a^O}{\\partial z^O}$ (see below), we see that both $a^O$ and $z^O$ are vectors. As before the vector denominator, $\\partial z^O$, creates two rows, while the vector numerator, $\\partial a^O$ creates two columns. In a similar manner as above, we can also see that two of the partial derivatives becomes zero. To express this in a matrix form, we make use to the Identity matrix, $I$; we multiply the dot-product (element-wise multiplication) of $a^O$ and $1-a^O$ vectors and then multiply this by $I$.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial a^O}{\\partial z^O} &=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^O}{\\partial z_1^O}, & \\frac{\\partial a_2^O}{\\partial z_1^O}\\\\\n",
    "\\frac{\\partial a_1^O}{\\partial z_2^O}, & \\frac{\\partial a_2^O}{\\partial z_2^O}\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\sigma(z_1^O)(1-\\sigma(z_1^O)), & 0\\\\\n",
    "0, &\\sigma(z_2^O)(1-\\sigma(z_2^O))\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "a_1^O(1-a_1^O), & 0\\\\\n",
    "0, &a_2^O(1-a_2^O)\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(a^O\\cdot(1-a^O)\\right)\\times I\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "The partial derivative $\\frac{\\partial z^O}{\\partial a^H}$ (see below), becomes a matrix in the same amnner as above for $\\frac{\\partial a^O}{\\partial z^O}$. However, there are no zero clls, instead each cell comprise a sum over index $j$, but one of the terms become zero, as above for $\\frac{\\partial L(b,w|x)}{\\partial a^O}$. In the end, it turns ut that the answer corresponds to the transpose of the matrix $w^O$\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial z^O}{\\partial a^H}\n",
    "&=& \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial z_1^O}{\\partial a_1^H}, & \\frac{\\partial z_2^O}{\\partial a_1^H}\\\\\n",
    "\\frac{\\partial z_1^O}{\\partial a_2^H}, & \\frac{\\partial z_2^O}{\\partial a_2^H}\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial \\sum_{j=1}^2 w_{j,1}^O a_j^H + b_1^O}{\\partial a_1^H}, & \n",
    "\\frac{\\partial \\sum_{j=1}^2 w_{j,2}^O a_j^H + b_2^O}{\\partial a_1^H}\\\\\n",
    "\\frac{\\partial \\sum_{j=1}^2 w_{j,1}^O a_j^H + b_1^O}{\\partial a_2^H}, &\n",
    "\\frac{\\partial \\sum_{j=1}^2 w_{j,2}^O a_j^H + b_2^O}{\\partial a_2^H}\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "w_{1,1}^O, &\n",
    "w_{1,2}^O \\\\\n",
    "w_{2,1}^O &\n",
    "w_{2,2}^O\n",
    "\\end{array}\\right)\\\\\n",
    "&=& \\left(w^O\\right)^T\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "The solution for $\\frac{\\partial a^H}{\\partial z^H}$ is completely analogous to solution for $\\frac{\\partial a^O}{\\partial z^O}$:\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial a^H}{\\partial z^H} &=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^H}{\\partial z_1^H}, & \\frac{\\partial a_1^H}{\\partial z_2^H}\\\\\n",
    "\\frac{\\partial a_2^H}{\\partial z_1^H}, & \\frac{\\partial a_2^H}{\\partial z_2^H}\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\sigma(z_1^H)(1-\\sigma(z_1^H), & 0\\\\\n",
    "0, &\\sigma(z_2^H)(1-\\sigma(z_2^H)\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "a_1^H(1-a_1^H), & 0\\\\\n",
    "0, & a_2^H(1-a_2^H)\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(a^O\\cdot(1-a^O)\\right)\\times I\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Finally, in the solution for $\\frac{\\partial z^H}{\\partial w^H}$, we get a $2\\times 2$ matrix with one cell per row equalling zero. The end result can be expressed as a påroduct of $i$ and $I$.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial z^H}{\\partial w^H} &=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial z_1^H}{\\partial w_{1,1}^H}, &\n",
    "\\frac{\\partial z_1^H}{\\partial w_{1,2}^H}\\\\\n",
    "\\frac{\\partial z_2^H}{\\partial w_{1,1}^H}, &\n",
    "\\frac{\\partial z_2^H}{\\partial w_{1,2}^H}\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial w_{1,1}^H i_1 + b_1^H}{\\partial w_{1,1}^H}, &\n",
    "\\frac{\\partial w_{1,1}^H i_1 + b_1^H}{\\partial w_{1,2}^H}\\\\\n",
    "\\frac{\\partial w_{1,2}^H i_1 + b_2^H}{\\partial w_{1,1}^H}, &\n",
    "\\frac{\\partial w_{1,2}^H i_1 + b_2^H}{\\partial w_{1,2}^H}\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "\\left(\\begin{array}{c}\n",
    "i_1, &\n",
    "0\\\\\n",
    "0, &\n",
    "i_1\n",
    "\\end{array}\\right)\\\\\n",
    "&=&\n",
    "i\\times I\n",
    "\\\\\n",
    "%\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "### 4. Multiply intermediate expressionto get final partial derivative \n",
    "\n",
    "So, to test that we really got it right, let's multiply all intermediate prstial derivatives matrices to get the final $\\frac{\\partial L(b,w|x)}{\\partial w^H}$ and see if it makes sense. This will be rather messy to write, so we will limit ourselves to use the unsolved versions of the partial likelilhood matrices; however, we will mark the zero-valued partial likelihood. We start with the full expression using the matrix names, and then expand the matrices from right to left and peform the multiplications. Matrices colored gtreen indicate the result of the matrix multiplication in the row above.\n",
    "\n",
    "$$\\begin{eqnarray}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial w^H} \n",
    "&=& \n",
    "\\frac{\\partial z^H}{\\partial w^H}\n",
    "\\times \n",
    "\\frac{\\partial a^H}{\\partial z^H} \n",
    "\\times \n",
    "\\frac{\\partial z^O}{\\partial a^H} \n",
    "\\times\n",
    "\\frac{\\partial a^O}{\\partial z^O} \n",
    "\\times \n",
    "\\frac{\\partial L(b,w|x)}{\\partial a^O}\\\\\n",
    "&=& \n",
    "\\frac{\\partial z^H}{\\partial w^H}\n",
    "\\times \n",
    "\\frac{\\partial a^H}{\\partial z^H} \n",
    "\\times \n",
    "\\frac{\\partial z^O}{\\partial a^H} \n",
    "\\times\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^O}{\\partial z_1^O}, & 0\\\\\n",
    "0, & \\frac{\\partial a_2^O}{\\partial z_2^O}\\\\\n",
    "\\end{array}\\right)\n",
    "\\times \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_1^O}\\\\\n",
    "\\frac{\\partial L(b,w|x)}{\\partial a_2^O}\\\\\n",
    "\\end{array}\\right)\\\\\n",
    "&=& \n",
    "\\frac{\\partial z^H}{\\partial w^H}\n",
    "\\times \n",
    "\\frac{\\partial a^H}{\\partial z^H} \n",
    "\\times \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial z_1^O}{\\partial a_1^H}, & \\frac{\\partial z_2^O}{\\partial a_1^H}\\\\\n",
    "\\frac{\\partial z_1^O}{\\partial a_2^H}, & \\frac{\\partial z_2^O}{\\partial a_2^H}\n",
    "\\end{array}\\right)\n",
    "\\times\n",
    "\\color{green}{\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^O}{\\partial z_1^O}\\frac{\\partial L(b,w|x)}{\\partial a_1^O}\\\\\n",
    "\\frac{\\partial a_2^O}{\\partial z_2^O}\\frac{\\partial L(b,w|x)}{\\partial a_2^O}\\\\\n",
    "\\end{array}\\right)\n",
    "}\n",
    "\\\\\n",
    "&=& \n",
    "\\frac{\\partial z^H}{\\partial w^H}\n",
    "\\times \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^H}{\\partial z_1^H}, & 0\\\\\n",
    "0, & \\frac{\\partial a_2^H}{\\partial z_2^H}\\\\\n",
    "\\end{array}\\right)\n",
    "\\times \n",
    "\\color{green}{\n",
    "\\left(\\begin{array}{c}\n",
    "\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_1^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\\\\n",
    "\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_2^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\end{array}\\right)\n",
    "}\\\\\n",
    "&=& \n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial z_1^H}{\\partial w_{1,1}^H}, & 0\\\\\n",
    "0, &\\frac{\\partial z_2^H}{\\partial w_{1,2}^H}\n",
    "\\end{array}\\right)\n",
    "\\times \n",
    "\\color{green}{\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial a_1^H}{\\partial z_1^H}\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_1^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\\\\n",
    "\\frac{\\partial a_2^H}{\\partial z_2^H}\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_2^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\end{array}\\right)\n",
    "}\\\\\n",
    "&=& \n",
    "\\color{green}{\n",
    "\\left(\\begin{array}{c}\n",
    "\\frac{\\partial z_1^H}{\\partial w_{1,1}^H} \\frac{\\partial a_1^H}{\\partial z_1^H}\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_1^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\\\\n",
    "\\frac{\\partial z_2^H}{\\partial w_{1,2}^H} \\frac{\\partial a_2^H}{\\partial z_2^H}\\sum_{j=1}^2 \\frac{\\partial z_j^O}{\\partial a_2^H}\\frac{\\partial a_j^O}{\\partial z_j^O}\\frac{\\partial L(b,w|x)}{\\partial a_j^O}\n",
    "\\end{array}\\right)\n",
    "}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Happily, the final expression for $\\frac{\\partial L(b,w|x)}{\\partial w_{11}^H}$ (first row) corresponds to the expression we gave above (under **What happens if we have more neurons per layer?**). \n",
    "Moreover, if we compare to the network figure below, the final expression does make sense:\n",
    "- there is a single trace from $w_{1,1}^H$ to $a_1^H$\n",
    "- however, from $a_1^H$ there are two paths, through $z_1^O$ and through $z_2^O$ and we need to sum over these.\n",
    "- from each of $z_1^O$ and $z_2^O$ there is then a single path to $\\hat{y}_1$ and $\\hat{y}_2$, respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is as far we will go. Feel free to program the variables and complete the steps **4. final partial derivative** and **5. Update the reaquested weights**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nn_dl_python] *",
   "language": "python",
   "name": "conda-env-nn_dl_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
