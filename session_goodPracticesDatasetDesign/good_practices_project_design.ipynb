{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Good practices of NN/DL project design\n",
    "## What to do and - more importantly perhaps - not to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Is my project right for Neural Networks?\n",
    "\n",
    "* The thought process should not be: “I have some data, why don’t we try neural networks”\n",
    "* But it should be: “Given the problem, does it make sense to use neural networks?”\n",
    "\n",
    "    * Do I really need non-linear modelling?\n",
    "    * What literature is out there for similar problems?\n",
    "    * How much data will I be able to gather or put my hands on?\n",
    "    * Are there datasets out there that I can re-use before I collect my data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Do I really need non-linear modelling?\n",
    "\n",
    "* Sometimes linear methods perform just as well if not better\n",
    "* Less risk of catastrophic overfitting\n",
    "* Faster to code, optimize, run, debug\n",
    "* Use linear modelling as a baseline before you move to non-linear methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Real-life example\n",
    "\n",
    "Drop-in question: \"I tried deep learning on my data and it didn't perform better than this other simpler method\"\n",
    "\n",
    "* Classifying gene expression samples\n",
    "* O(1000) features\n",
    "* O(1000) samples\n",
    "* 2 classes\n",
    "* NN looked like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 1000)              5001000   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 5,502,502\n",
      "Trainable params: 5,502,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim=5000))\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parameters (weights) vs. samples\n",
    "\n",
    "* If the number of parameters is many times higher than the number of samples a NN will never work\n",
    "* Ideally, we are looking for the inverse: way more samples than parameters\n",
    "* Some rule of thumbs out there:\n",
    "    * 10x as many labelled samples as there are weights\n",
    "    * A few thousand samples per class\n",
    "    * Just try it and downscale/regularize until you're not overfitting anymore (or until you have a linear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And even if I have enough data for a NN...\n",
    "\n",
    "... is Deep Learning the right choice?\n",
    "\n",
    "* The tasks were Deep Learning shine are those that require feature extraction:\n",
    "    * Imaging -> edge/object detection\n",
    "    * Audio/text -> sound/word/sentence detection\n",
    "    * Protein structure prediction -> mutation patterns/local structure/global structure\n",
    "\n",
    "* Deep Learning makes feature extraction automatic and seem to work best when there is a hierarchy to these features\n",
    "* Is your data made that way? \n",
    "    * Does it have an order (spatial/temporal)? \n",
    "    * Are smaller patterns going to form higher-order patterns?\n",
    "* All these different types of layers need to be there for a reason\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And even when both these conditions have met\n",
    "\n",
    "... you need a few more things:\n",
    "\n",
    "* Domain knowledge is not enough\n",
    "* Sometimes people with NN/DL knowledge and no domain knowledge end up being the right ones for the job (see Alphafold)\n",
    "* You also need lots of patience and time, these things rarely work out of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A few more things to keep in mind\n",
    "\n",
    "* You need extensive knowledge of your data:\n",
    "    * Split the data in a rigorous way to avoid introducing biases\n",
    "    * Check for _information leakage_ before you get overly optimistic results\n",
    "    * Make sure that there are no errors in your data\n",
    "\n",
    "And therein lies the main issue:\n",
    "* Some think that DL is about having a model magically fixing your data\n",
    "* Instead, DL is _mostly_ about knowing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets are very good at detecting patterns and they will use this against you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 1: looking for target leakage in a text dataset (~1 h.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Know your train/validation/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: how to rigorously split a protein dataset (~1 h.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Having the right data for NN/DL, but not enough of it: now what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3: transfer learning in imaging data (~1 h.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips and tricks on training your Neural Networks"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:nn_dl_python] *",
   "language": "python",
   "name": "conda-env-nn_dl_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
